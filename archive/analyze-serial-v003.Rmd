---
title: "R Notebook"
output: html_notebook
---

```{r}
library(clue)     
library(gplots)
library(signal)
library(calibrate)
library(caTools)
library(xtable)
library(robustbase)
library(MASS)
library(bmp)
library(tools)
library(imager)
library(R.utils)
#library(xlsx)
sourceDirectory("R")
```

Inputs:
```{r}
dataRate = 500 # Hz
minCarrier = 640e3 # Hz
minSensitivityEstimate = .52 # Hz/pg
 

# file processing parameters
experimentTimeWindow = c(0/60,12) # hr - start and end of experiment/analysis. Set end way too big to use whole file.
padTrimmedData<- TRUE # Whether to pad the trimmed data so the file length aligns with metadata

# detection parameters
detectionThreshold = -3
tDoubletGap = c(50,1000)
maxHeightDiff = .5
medLength = 7;
sgLength = 51;
sgOrder = 3;
quantileWidth=500
quantileDownsamplingFactor=21;
quantileProb = .95
baselineSearchWidthSidePoints = 600; # 0.8 seconds on either side
numBaselineChunks = 20; 
tipSidePointFractionOfPeakWidth = 0.15

# calibration parameters
beadcalibtype <-1
# sensitivityfile<-"D:/Dropbox (MIT)/Nick SMR Data/fSMR/180321 - 20x test/Mode-sensitivities_fromP130.csv"
#Bead detection mode, 1= time&mass, 2= mass only
beadDetect<-1
beadTimeWindow<-c(0,3)
cellTimeWindow<-c(3,12)

# matching parameters
cellSizeRange    = c(7,100) #pg
sensorsToDrop    = NULL # set to NULL to not drop any
mass.sd          = 0.25
gr.mu.prior      = 0
gr.sd.prior      = 10
timeGap.mu       = 1.6/60
timeGap.sd       = .7/60
gapCost          = 1
trapLengthCutoff = 6



```

```{r}
	removePacketIndices = function(x) {
	  "%+%" <- function(x,y) paste(x,y,sep="")
	  packetIndices = x[seq(1, length(x), by=129)]
		filteredData = x[-seq(1, length(x), by=129)]
	  g = diff(packetIndices)
		if (!all(g %in% c(1, -65535)))
			warning("POSSIBLE PACKET LOSS - lost sets of " %+% paste(names(table(g))[-c(1,2)], collapse=","))
		filteredData
	}

"%+%" <- function(x,y) paste(x,y,sep="")
"%within%" <- function(x,y) (x >= y[1] & x <= y[2])


dat.decimated = list() # we'll keep this around for plotting purposes
dat.bp.decimated = list() # we'll keep this around for plotting purposes
detectedPeaks = list()

directory = "C:/Users/Max/Documents/R/serial-nd/test-datasets/200211_GL"

o=c(12,11,10,9,8,7,1,2,3,4,5,6)#for Greenline mid 2019-2020
files = list.files(directory,full.names=TRUE, pattern="*.bin")
files = files[o]


par(mfrow=c(6,5), mgp=c(1.5,.2,0), tck=-.015, mar=c(3,3,.5,.5), cex.lab=.8, cex.axis=.8)
carriers = vector('double',length(files))
singletsDetected = vector('double',length(files))

for(f in 1:length(files)) {
  cat("loading "%+%f%+%"...")
  
	# read in signals
	dat = readBin(files[f], n=3e7, what='integer', endian='swap')
	dat = removePacketIndices(dat)*12.5e6/2^32  #conversion factor from int to frequency
	
	if (f==length(files)){
	  last.dat<-dat
	}

	# crop signal to the times in experimentTimeWindow
  dat = dat[(experimentTimeWindow[1]*dataRate*3600 + 1):min(length(dat),(experimentTimeWindow[2]*dataRate*3600))]
  
  # "pad" data if desired (if padTrimmedData == TRUE)
  if (padTrimmedData==TRUE){
  	frontPad<-rep(dat[experimentTimeWindow[1]*dataRate*3600],experimentTimeWindow[1]*dataRate*3600)
  	backPad<-rep(dat[min(length(dat),(experimentTimeWindow[2]*dataRate*3600))],length(dat)-min(length(dat),(experimentTimeWindow[2]*dataRate*3600)))
	
    if (length(frontPad)!=0){
     dat<-c(frontPad,dat,backPad) 
    }
    if (length(backPad)>0){
      dat<-c(dat,backPad)
    }
  }
  
  # decimate data
	dat.decimated[[f]] = colMeans(matrix(dat[1:(plotDec*floor(length(dat)/plotDec))], nrow=plotDec)) 

	# approximately normalize signals
	carriers[f] = median(dat[(length(dat)-1e4):length(dat)])
	dat = dat / (carriers[f]/minCarrier)^1.5/minSensitivityEstimate # relative, ballpark sensitivity estimate

	cat(" filtering...")
	
	### filter section ###
	# nonlinear then linear low-pass filter
	dat.lp = signal::sgolayfilt(runmed(dat, k=medLength),p=sgOrder, n=sgLength)

	# nonlinear high-pass filter
  i = seq(floor(quantileDownsamplingFactor/2),length(dat.lp), by=quantileDownsamplingFactor)
  dat.hp = rep(runquantile(dat.lp[i], k=floor(quantileWidth/quantileDownsamplingFactor), probs=quantileProb),each=quantileDownsamplingFactor)[1:length(dat.lp)]
	dat.bp =  dat.lp - dat.hp
	dat.bp.decimated[[f]] = colMeans(matrix(dat.bp[1:(plotDec*floor(length(dat.bp)/plotDec))], nrow=plotDec))

	# detect peaks
	cat(" detecting...\n")
  peakDetectionResults = getPeaks(
        	dat.bp,
        	dat,
        	detectionThreshold=detectionThreshold, 
		tDoubletGap=tDoubletGap, 
		maxHeightDiff=maxHeightDiff,
		baselineSearchWidthSidePoints=baselineSearchWidthSidePoints,
		numBaselineChunks= numBaselineChunks,
		tipSidePointFractionOfPeakWidth=tipSidePointFractionOfPeakWidth,
        	visualizeNum=0
	)
  
  singletsDetected[f] = peakDetectionResults$singletsDetected
  detectedPeaks[[f]] = peakDetectionResults$peakParamDataFrame
  detectedPeaks[[f]] = detectedPeaks[[f]][detectedPeaks[[f]][,2] > abs(detectionThreshold), ]
  detectedPeaks[[f]]
}
```




```{r}

# plotting parameters
plotDec = 20
n = length(files)+1
cols = rgb(0:n/n,c(1:(n/2)/(n/2),(n/2):1/(n/2)),n:0/n)
cols[1] = 'black'
cols[sensorsToDrop] = '#00000000'
sensorsToKeep = which( !(1:length(files) %in% sensorsToDrop))

par(mfrow=c(2,2))
plot(-1,-1,xlab='time gap between antinodes (indices)', ylab='probability density', xlim=tDoubletGap,ylim=c(0,5/(tDoubletGap[2]-tDoubletGap[1])))
for (i in 1:length(files)){
  lines(density(detectedPeaks[[i]]$gap), col=cols[i])
}

xlim=range(sapply(detectedPeaks, function(x) range(x$baselineSlope)))
plot(-1,-1, xlim=xlim, ylim=c(0,10/max(xlim)), xlab='baseline slope', ylab='probability density')
for (i in 1:length(files)){
  lines(density(detectedPeaks[[i]]$baselineSlope), col=cols[i])
}

xlim=range(sapply(detectedPeaks, function(x) range(x$massRaw)))
ylim=range(sapply(detectedPeaks, function(x) range(x$massRaw2-x$massRaw1)))

plot(-1,-1,xlim=xlim, ylim=ylim, xlab='rough mass estimate (pg)', ylab='Peak height mismatch (~pg)')
for (i in 1:length(files)){
  points(detectedPeaks[[i]]$massRaw, detectedPeaks[[i]]$massRaw2-detectedPeaks[[i]]$massRaw1, pch=16,cex=.5, col=cols[i])
}
```

```{r}
beadDetect = T
# calibration parameters
mediaDensity = 1.003;       # g/mL (RPMI+10%FBS is 1.003g/mL, ballparked YPD = 1.01)
calibrationBounds = c(7.5,9.5)
calibrationBeadDiameter = 6.98 # um
calibrationBeadCV = 0.01 #CV in decimal, ie .01=1%
densityBandwidth = .1
beadMaterialDensity<- 1.05

par(mfrow=c(4,3), mar=c(4,4,1,1), mgp=c(1.5,.5,0), tck=-.015)

detectedcellpeaks<-list()
detectedbeadpeaks<-list()

if (beadDetect== 1){ 
  for (i in 1:length(files)){
    detectedcellpeaks[[i]]<-subset(detectedPeaks[[i]],detectedPeaks[[i]]$massRaw>calibrationBounds[2]|detectedPeaks[[i]]$massRaw<calibrationBounds[1]|detectedPeaks[[i]]$time<beadTimeWindow[1]|detectedPeaks[[i]]$time>beadTimeWindow[2])
       detectedbeadpeaks[[i]]<-subset(detectedPeaks[[i]],detectedPeaks[[i]]$massRaw<calibrationBounds[2]&detectedPeaks[[i]]$massRaw>calibrationBounds[1]&detectedPeaks[[i]]$time>beadTimeWindow[1]&detectedPeaks[[i]]$time<beadTimeWindow[2])
    }
  origdetectedcell<-detectedcellpeaks
  origdetectedbead<-detectedbeadpeaks
} else if (beadDetect == 2){  
    for (i in 1:length(files)){ 
    detectedcellpeaks[[i]]<-subset(detectedPeaks[[i]],detectedPeaks[[i]]$massRaw>calibrationBounds[2]|detectedPeaks[[i]]$massRaw<calibrationBounds[1])
    detectedbeadpeaks[[i]]<-subset(detectedPeaks[[i]],detectedPeaks[[i]]$massRaw<calibrationBounds[2]&detectedPeaks[[i]]$massRaw>calibrationBounds[1])
    }  
  origdetectedcell<-detectedcellpeaks
  origdetectedbead<-detectedbeadpeaks
} 

```


```{r}
# outlier rejection parameters
outlierDetectionThreshold= -2000  # log of probability cutoff - set to NA to not use.
outlierDetectionThresholdBead= -2000
#Node deviation removal for bead doublet/triplets - set to -1 to not use
ndevpermasscutoff<- -.2


nPeaksDropped = NULL
for (i in 1:length(files)){ 
  # use nodeDev, baselineSlope, gap, and antinode difference
  d=detectedcellpeaks[[i]][,c("baselineSlope","gap","antinodeDifferenceRaw")]
  mu = apply(d,2,median)
  mhDist = mahalanobis(d, mu,cov.rob(d)$cov)
  
  h=hist(mhDist,plot=FALSE,breaks=2000)
  plot(h$mids,h$counts, log='xy',type='o',xlab='Mahalanobis distance (robust)', ylab='Count',col=cols[i])
  if (is.na(outlierDetectionThreshold)) {
    nPeaksDropped = c(nPeaksDropped,0)
    next
  }
  mhDistCutoff = qchisq(outlierDetectionThreshold,df=ncol(d),lower.tail=FALSE,log=TRUE)
  abline(v=mhDistCutoff)
  lines(h$mids, dchisq(h$mids,df=ncol(d))*nrow(d)*diff(h$mids)[1],col='red')
  
  keepPeaks = which(mhDist<mhDistCutoff)
  nPeaksDroppedcell = c(nPeaksDropped, sum(mhDist>=mhDistCutoff))
  detectedcellpeaks[[i]] = detectedcellpeaks[[i]][keepPeaks,] 
} 

```

```{r}
for (i in 1:length(files)){ 
  # use nodeDev, baselineSlope, gap, and antinode difference
  d=detectedbeadpeaks[[i]][,c("baselineSlope","gap","antinodeDifferenceRaw")]
  mu = apply(d,2,median)
  mhDist = mahalanobis(d, mu,cov.rob(d)$cov)
  
  h=hist(mhDist,plot=FALSE,breaks=2000)
  plot(h$mids,h$counts, log='xy',type='o',xlab='Mahalanobis distance (robust)', ylab='Count',col=cols[i])
  if (is.na(outlierDetectionThreshold)) {
    nPeaksDropped = c(nPeaksDropped,0)
    next
  }
  mhDistCutoff = qchisq(outlierDetectionThresholdBead,df=ncol(d),lower.tail=FALSE,log=TRUE)
  abline(v=mhDistCutoff)
  lines(h$mids, dchisq(h$mids,df=ncol(d))*nrow(d)*diff(h$mids)[1],col='red')
  
  keepPeaks = which(mhDist<mhDistCutoff)
  nPeaksDroppedbead = c(nPeaksDropped, sum(mhDist>=mhDistCutoff))
  detectedbeadpeaks[[i]] = detectedbeadpeaks[[i]][keepPeaks,] 
  detectedPeaks[[i]] = rbind(detectedbeadpeaks[[i]],detectedcellpeaks[[i]])
} 

```
```{r}
par(mfrow=c(1,1), tck=-.015, mgp=c(2,.8,0))
ymin = min(sapply(dat.decimated,function(x) min(x-x[1])))
ymax = max(sapply(dat.decimated,function(x) max(x-x[1])))
for (i in 1:length(files)){
  d = dat.decimated[[i]]
  if (i==1)
	  plot(1:length(d)*plotDec/dataRate/60, d-d[1], type='l', bty='n', col=cols[i], 
         ylim=c(ymin,ymax), ylab='Frequency (Hz)', xlab='Time (minutes)')
  else {
    lines(1:length(d)*plotDec/dataRate/60, d-d[1],col=cols[i])
  }
}
```

```{r}
par(mfrow=c(length(sensorsToKeep),1), mar=c(1,3,0,1), oma=c(3,3,1,0), tck=-.015, mgp=c(2,.8,0))
ymin = round(range(unlist(lapply(detectedPeaks, function(x){quantile(x[,2],.98)} )))[2],2) # round to nearest 10
for (i in sensorsToKeep){
	d = dat.bp.decimated[[i]]
	plot(1:length(d)*plotDec/dataRate/60, d, type='l', ylim=c(-ymin,0), bty='n', ylab='', xlab='',
		xaxt=ifelse(i==length(files),'s','n'), yaxt='n',col=cols[i])
	abline(h=detectionThreshold, lty=2, col='grey')
	points(detectedPeaks[[i]][,1]*60, -pmin(detectedPeaks[[i]][,2],ymin), col='dodgerblue', pch=16, cex=.8)
	#textxy(detectedPeaks[[i]][,1]*60, -pmin(detectedPeaks[[i]][,2],ymin), 1:nrow(detectedPeaks[[i]]), cex=1)
	axis(2, las=2, at=c(0,-ymin))
}
mtext(side=1, 'Time (minutes)', adj=.5, line=2.3)
mtext(side=2, 'Buoyant mass (pg)', adj=.5, line=.5, outer=T)
```

```{r}

par(mfrow=c(length(sensorsToKeep),1), mar=c(1,3,0,1), oma=c(3,3,1,0), tck=-.015, mgp=c(2,.2,0))
ymin = max(unlist(lapply(detectedPeaks, function(x){max(x[,2])} )),na.rm=T)
for (i in sensorsToKeep){
  d = detectedPeaks[[i]]$massRaw[detectedPeaks[[i]]$massRaw > 0] 
  if (length(d)==0) {
    plot(1,1)
    next
  }
  h=hist(d, xlim=c(0,ymin), main="", breaks=200,col=cols[i])
  lines(0:ymin, ecdf(d)(0:ymin)*max(h$counts), col='blue',lty=2)
  abline(v=calibrationBounds, col='red')
}
mtext(side=1, 'Buoyant mass (pg)', adj=.5, line=.5, outer=T)
```

```{r}
mb = 4/3*pi*(calibrationBeadDiameter/2*1e-4)^3* (beadMaterialDensity-mediaDensity) *1e12 	# pg /bead
experimentTotalTime = length(dat.bp.decimated[[1]])*plotDec/dataRate/3600 

par(mfrow=c(3,1), mgp=c(1.5,.2,0), tck=-.015, mar=c(3,3,.5,.5), cex.lab=.8, cex.axis=.8)
estimatedSensitivities = rep(1,n-1)

par(mfrow=c(4,3))

for (i in sensorsToKeep){

# NLC edit 07/27/16
	a= detectedPeaks[[i]]$massRaw

  if (length(a)== 0) next
	a = a[a>calibrationBounds[1] & a<calibrationBounds[2] & 
          experimentTotalTime - detectedPeaks[[i]]$time > (length(files)-i)*timeGap.mu ]
 dens = density(a, bw=densityBandwidth, n=2^13);
  
 plot(dens,xlim=c(calibrationBounds),col=cols[i],lwd=2); 
  legend('topright', c("bw="%+%round(dens$bw,3), "n="%+%length(a),"mad="%+%round(mad(a),4)), bty='n')
  abline(v=dens$x[which.max(dens$y)])
  estimatedSensitivities[i] = dens$x[which.max(dens$y)]/mb

  
beadmassraw <- detectedPeaks[[i]]$massRaw
beadtime <- detectedPeaks[[i]]$time
beadcarrier <-detectedPeaks[[i]]$baseline
beads<-data.frame(beadmassraw,beadtime,beadcarrier)
beads<-beads[which(beadmassraw>calibrationBounds[1]&beadmassraw<calibrationBounds[2]),]
mod<-lm(beads[,1]~beads[,2])
plot(beads[,2],beads[,1],ylim=calibrationBounds)
abline(mod,lty=2,lwd=3,col='red')
abline(h=dens$x[which.max(dens$y)],lty=2)
legend('topright',c('Sensitivity =',round(coef(mod)[1],digits=3),'-',round(coef(mod)[2],digits=3),'*time'))
plot(beads[,3],beads[,1],xlim=c(max(beads[,3]),min(beads[,3])))
mod2<-lm(beads[,1]~beads[,3])
abline(mod2,lty=2,lwd=3,col='red')
abline(h=dens$x[which.max(dens$y)],lty=2)
legend('topright',c('Sensitivity =',round(coef(mod2)[1],digits=3),'-',round(coef(mod2)[2],digits=3),'*carrier'))


if (beadcalibtype == 2){
  
  detectedPeaks[[i]]$mass = detectedPeaks[[i]][,2]/((coef(mod)[2]*detectedPeaks[[i]]$time+coef(mod)[1])/mb)
  #detectedPeaks[[i]]$mass = detectedPeaks[[i]][,2]
  dat.bp.decimated[[i]] = dat.bp.decimated[[i]]/estimatedSensitivities[i] # we'll save this later, make sure we save it in units of pg
  detectedPeaks[[i]]$nodeDev = detectedPeaks[[i]]$nodeDev/((coef(mod)[2]*detectedPeaks[[i]]$time+coef(mod)[1])/mb)
#   legend('topright', c("bw="%+%round(dens$bw,3), "n="%+%length(a),"mad="%+%round(mad(a),4)), bty='n')
} else if (beadcalibtype == 1){
  
  detectedPeaks[[i]]$mass = detectedPeaks[[i]][,2]/estimatedSensitivities[i]
  #detectedPeaks[[i]]$mass = detectedPeaks[[i]][,2]
  dat.bp.decimated[[i]] = dat.bp.decimated[[i]]/estimatedSensitivities[i] # we'll save this later, make sure we save it in units of pg
  detectedPeaks[[i]]$nodeDev = detectedPeaks[[i]]$nodeDev/estimatedSensitivities[i]

  
}else if (beadcalibtype == 3){
detectedPeaks[[i]]$mass = detectedPeaks[[i]][,2]/((coef(mod2)[2]*detectedPeaks[[i]]$baseline+coef(mod2)[1])/mb)
  #detectedPeaks[[i]]$mass = detectedPeaks[[i]][,2]
  dat.bp.decimated[[i]] = dat.bp.decimated[[i]]/estimatedSensitivities[i] # we'll save this later, make sure we save it in units of pg
  detectedPeaks[[i]]$nodeDev = detectedPeaks[[i]]$nodeDev/((coef(mod2)[2]*detectedPeaks[[i]]$baseline+coef(mod2)[1])/mb)
}
else if (beadcalibtype == 4){
  importedsens<-read.csv(file = sensitivityfile)
  importedsens<-as.numeric(importedsens[,2])
  estimatedSensitivities<-(importedsens)/((carriers/minCarrier)^1.5*minSensitivityEstimate)
detectedPeaks[[i]]$mass = detectedPeaks[[i]][,2]/estimatedSensitivities[i]
  #detectedPeaks[[i]]$mass = detectedPeaks[[i]][,2]
  dat.bp.decimated[[i]] = dat.bp.decimated[[i]]/estimatedSensitivities[i] # we'll save this later, make sure we save it in units of pg
  detectedPeaks[[i]]$nodeDev = detectedPeaks[[i]]$nodeDev/estimatedSensitivities[i]

}
}
```
```{r}
par(mfrow=c(1,1))
sensitivities = (carriers/minCarrier)^1.5*minSensitivityEstimate*estimatedSensitivities
plot(carriers/1e3, sensitivities, log='xy', ylab='Sensitivity (Hz/pg)', xlab='Carrier frequency (kHz)',col=cols,pch=16,xlim=c((minCarrier/1E3-25),(max(carriers)/1E3+50)),ylim=c(0.4,1))
freqRange = seq(min(carriers),max(carriers),length.out=100)/1e3
lines(freqRange, (freqRange*1e3/minCarrier)^1.5*minSensitivityEstimate, lty=2)
write.csv(cbind(sensitivities,carriers),paste(directory,"Mode-sensitivities.csv"))
```

```{r}
par(mfrow=c(6,4), mar=c(3,3,1,1), mgp=c(1.5,.2,.0), tck=-.015)

for (i in sensorsToKeep){  
  d= detectedPeaks[[i]]
  q<-subset(d,d$mass>calibrationBounds[2])
  plot(d$mass, d$nodeDev, xlab='Buoyant mass (pg)', ylab='nodal deviation from baseline (pg)', 
       pch=16,cex=.5, main='sensor '%+%i,col=cols[i])
  abline(h=0, lty=2, col='grey') 
  abline(v=cellSizeRange, lty=2, col='grey')
  abline(a=0,b=ndevpermasscutoff*carriers[i]/(mean(carriers)))
  plot(q$nodeDev/q$mass)
  abline(h=ndevpermasscutoff*carriers[i]/(mean(carriers)),col='red',lty=2)
  detectedPeaks[[i]]<-rbind(subset(q,q$nodeDev/q$mass>=ndevpermasscutoff*carriers[i]/(mean(carriers))),subset(d,d$mass<calibrationBounds[2]))
                      
  } 
    

```

```{r}
experimentTotalTime = length(dat.bp.decimated[[1]])*plotDec/dataRate/3600 
par(mfrow=c(1,1))
for (i in length(files):1){
  p = detectedPeaks[[i]]
  if(i==length(files))
    plot(p$time, p$mass, pch=16,  ylim=range(c(mb, cellSizeRange)), col=cols[i], log='',
         xlab='time (h)', ylab='buoyant mass (pg)', xlim=c(0,experimentTotalTime))
  if (i!=length(files))
    points(p$time, p$mass, pch=16, col=cols[i])


}
abline(h=mb, col='grey', lty=2,lwd=2)
```
```{r}



cell = function(m, t, i, sensor=NULL, nSensors=NULL){
	# two use cases - fully populated m, t and i vectors (including NAs), or
  #                 scalar m,t,i, and nonzero sensor, nSensors
  if (length(m)!=length(t) || length(m)!=length(i)) stop("mass, time and index lengths don't match.")
	if (all(which(!is.na(m)) != which(!is.na(t)))) stop("mass and time don't agree on which measurements were made.")
	if (length(m) == 1 & (is.null(sensor) | is.null(nSensors)) ) stop('single peak initializiation requires both sensor and nSensors to be specified')

  	if (length(m) == 1 ){
    		na = rep(NA, nSensors)
    		m.temp = na; m.temp[sensor] = m; m=m.temp;
		t.temp = na; t.temp[sensor] = t; t=t.temp;
    		i.temp = na; i.temp[sensor] = i; i=i.temp;
  	}
    
	sensorsUsed = which(!is.na(m))
	nSensorsUsed = length(sensorsUsed)
	gr = rep(NA,4);
	if (nSensorsUsed>1) gr = coef(summary(lm(m~t)))[2,]
	
	a = list(mass = m, time=t, indices = i,
			avgMass = mean(m, na.rm=T), 
			avgTime=mean(t, na.rm=T),
			gr=gr,
			sensorsUsed = sensorsUsed, 
			nSensorsUsed = nSensorsUsed,
			lastSensorUsed = max(sensorsUsed),
			lastMass = m[max(which(!is.na(t)))],
			lastTime = t[max(which(!is.na(t)))],
      picture=NULL)
	class(a) = "cell"
	a
}

joinCells = function(c1, c2){
  	if (class(c1) != 'cell' || class(c2)!= 'cell' ) stop("c1 and c2 must be cell objects.")
	if ( any( c1$sensorsUsed %in% c2$sensorsUsed)) stop('cant merge: overlapping measurements.')
	
	m = c1$mass; 
	m[c2$sensorsUsed] = c2$mass[c2$sensorsUsed];
	t=c1$time
	t[c2$sensorsUsed] = c2$time[c2$sensorsUsed];
	i = c1$indices; 
	i[c2$sensorsUsed] = c2$indices[c2$sensorsUsed];
	cell(m,t,i)
}	

plot.cell = function(c1, pad.x=.2, pad.y=.3, annotate=TRUE, ...){
  xlim = range(c1$time,na.rm=T) + c(-1,1)*diff(range(c1$time,na.rm=T))*pad.x
  ylim = range(c1$mass,na.rm=T) + c(-1,1)*diff(range(c1$mass,na.rm=T))*pad.y
	plot(c1$time, c1$mass, xlim=xlim, ylim=ylim,  ...)
  abline(v=c1$time, lty=2,col='grey')
	text(c1$time, c1$mass, 1:length(c1$mass),pos=4,cex=.7)
	if (c1$nSensorsUsed>1) abline(lm(c1$mass ~ c1$time), col='red');
  if (annotate & c1$nSensorsUsed > 2){
    RMSE = sd(residuals(lm(na.omit(c1$mass)~na.omit(c1$time))))
    text(xlim[1],ylim[1], srt=90, "GR="%+%round(c1$gr[1],3)%+%"\nRMSE="%+%round(RMSE,5), pos=4,cex=.8)
  }
}

points.cell = function(c1,...){
  points(c1$time, c1$mass, ...)
  abline(v=c1$time, lty=2,col='grey')
	text(c1$time, c1$mass, 1:length(c1$mass),pos=4,cex=.8)
	if (c1$nSensorsUsed>1) abline(lm(c1$mass ~ c1$time), col='red');
}

detectedPeaksToCellList = function(peakData,sensor,cellSizeRange){
	cells = list()
	i = 1
	for (j in 1:nrow(peakData)){
		if (peakData$mass[j] > cellSizeRange[1] & peakData$mass[j] < cellSizeRange[2]){
  			cells[[i]] = cell(m=peakData$mass[j], 
                       		t=peakData$time[j],
                       		i=j,
                       		sensor=sensor,
                       		nSensors=length(files)
                  			)
			i=i+1
		}
	}
	cells
}


peakMatchingCostMatrix = function(cellList, newCellList, mass.sd, gr.sd.prior, gr.mu.prior, timeGap.mu, timeGap.sd, gapCost) {
	n1 = length(cellList)
  n2 = length(newCellList)
  m = matrix(nrow=length(cellList),ncol=length(newCellList))

  for (i in 1:length(cellList)){
    for (j in 1:length(newCellList)){
      m[i,j] = -cellMatchLogLik(newCellList[[j]], cellList[[i]], mass.sd, gr.sd.prior, gr.mu.prior, timeGap.mu, timeGap.sd)
    }
  }
    
	m[is.infinite(m)] = 1e12; # very unlikely but possible if two peaks occur simultaneously

	mat = matrix(gapCost, nrow=2*max(n1, n2), ncol=2*max(n1,n2))
	mat[1:n1, 1:n2] = m;
	mat[(n1+1):nrow(mat), (n2+1):ncol(mat)] = 0
	mat
}




cellMatchLogLik = function(newCell, oldCell, mass.sd, gr.sd.prior, gr.mu.prior,timeGap.mu, timeGap.sd){
  
  tPrev = oldCell$time[oldCell$sensorsUsed]
	mPrev = oldCell$mass[oldCell$sensorsUsed]
	tNew = newCell$time[newCell$lastSensorUsed]
	mNew = newCell$mass[newCell$lastSensorUsed]
  timeGap = (tNew - oldCell$time[oldCell$lastSensorUsed])
  if (timeGap < 0) return(-1e5)
  sensorGap = newCell$lastSensorUsed - oldCell$lastSensorUsed
    
	# mean-center time such that growth rate and intercept parameters are uncorrelated;
	tNew = tNew-mean(tPrev); tPrev = tPrev-mean(tPrev); 

	# posterior parameters for growth rate (based on normal prior with known regression variance)
	gr.sd = 1 / sqrt( 1/gr.sd.prior^2 + t(tPrev)%*%tPrev/mass.sd^2 )
	gr.mu = gr.sd^2 * (gr.mu.prior/gr.sd.prior^2 + t(tPrev)%*%mPrev/mass.sd^2)

	# ballparked posterior parameters for intercept (mean mass)
	m.mu = mean(mPrev, na.rm=T)
	m.sd = mass.sd/sqrt(length(mPrev))

	# assuming 
	mNew.mu = gr.mu*tNew + m.mu
	mNew.sd = sqrt(tNew^2*gr.sd^2 + m.sd^2 + mass.sd^2)
  logLikelihood = dnorm(mNew, mNew.mu, mNew.sd,log=TRUE) + dnorm(timeGap/sensorGap, timeGap.mu,timeGap.sd,log=TRUE)
  
	return( logLikelihood  )
}




# first initialize the list to include all peaks in the first cantilever
beadSizeRange = (mb*range(calibrationBounds)/mean(calibrationBounds))
firstSensor=1; secondSensor=2;
if (length(sensorsToDrop)>0){
  firstSensor = (1:length(files))[-sensorsToDrop][1]
  secondSensor = (1:length(files))[-sensorsToDrop][2]
}
d = detectedPeaks[[firstSensor]]
d<-subset(d,d$mass>beadSizeRange[2]|d$mass<beadSizeRange[1]|d$time<beadTimeWindow[1]|d$time>beadTimeWindow[2])
d<-subset(d,d$time>cellTimeWindow[1]&d$time<cellTimeWindow[2])


cellList = detectedPeaksToCellList(d,firstSensor,cellSizeRange)

par(mfrow=c(4,3))

for (i in secondSensor:length(files)){
	if (i %in% sensorsToDrop) next
  
	#initialize every peak in sensor i as its own cell
  d = detectedPeaks[[i]]
  d<-subset(d,d$mass>beadSizeRange[2]|d$mass<beadSizeRange[1]|d$time<beadTimeWindow[1]|d$time>beadTimeWindow[2])
  d<-subset(d,d$time>cellTimeWindow[1]&d$time<cellTimeWindow[2])

	newCellList = detectedPeaksToCellList(d,i,cellSizeRange)

  cat('matching '%+%length(cellList) %+% ' existing cells with ' %+% length(newCellList) %+% ' in sensor ' %+% i %+% "\n")
  # now we're going to match up newCellList with cellList
	costs = peakMatchingCostMatrix(cellList, newCellList, mass.sd, gr.sd.prior, gr.mu.prior, timeGap.mu, timeGap.sd, gapCost)
	solution = solve_LSAP(costs - min(costs))
	hist(costs[cbind(1:length(cellList),solution[1:length(cellList)])], xlab='solution costs', main='matching to sensor '%+%i,breaks=50)
	# for every cell in the cellList, update it if we matched it
	for (j in 1:length(cellList)){
		if (solution[j] <= length(newCellList)) {# then we've matched it.
			cellList[[j]] = joinCells(cellList[[j]], newCellList[[solution[j]]])
		}  # otherwise, do nothing (unmatched cells stay in the cellList) 
	}

	# for every cell in the newCellList, if we didn't match it, add it to cellList
	for (j in (length(cellList)+1):nrow(costs)){ # check every gap in "from" sensor
		if (solution[j] <= length(newCellList))
			cellList[[length(cellList)+1]] = newCellList[[ solution[j] ]]		
	}
}

par(mfrow=c(1,1))
plot(0,0, xlim=c(0,experimentTotalTime), ylim=cellSizeRange, xlab='time (hours)', ylab='buoyant mass (pg)', log='')
for (i in cellList) {
	if (i$nSensorsUsed>=trapLengthCutoff) {
    points(i$time, i$mass, col=cols[sample((1:length(files))[sensorsToKeep],1)], pch=16); 
    lines(na.omit(i$time), predict(rlm(i$mass~i$time)), lwd=2, col=adjustcolor('black',0.4))
    text(na.omit(i$time), na.omit(i$mass), labels=i$sensorsUsed, cex=.5)
  } else {
    points(i$time, i$mass, col='#33333333', pch=16); 
    text(na.omit(i$time), na.omit(i$mass), labels=i$sensorsUsed, cex=.5)
  }
}

```

```{r}
nSensorsUsed = sapply(cellList,function(x){x$nSensorsUsed})
cellTrapDurations = sapply(cellList,function(x){diff(range(x$time,na.rm=T))})*60
boxplot(cellTrapDurations ~ factor(nSensorsUsed,levels=1:length(sensorsToKeep)),ylab='cell measurement duration (min)', pch="x",xlab='number of sensors used')
axis(3,at=as.numeric(names(table(nSensorsUsed))),labels=paste('n=', table(nSensorsUsed),sep=''),las=2)  
```

```{r}
# Number of single cell trajectories to plot
numSingleTraj = 1

#Number of standard deviations above the mean MAR error to prune out
sdtoprune = 3


par(mfrow=c(9,5), mar=c(1,1,0,0), tck=.01, mgp=c(1,0,0))
coefs = array(dim=c(0,7))
j=1
nPlotted=0
for(i in cellList){
  if (i$nSensorsUsed < trapLengthCutoff) next
	m = i$mass
	t= i$time-mean(i$time, na.rm=T)
  mod=lm(m~t)
  if (nPlotted < numSingleTraj){
    plot(i,pad.x=.5,pad.y=.5)
    for (k in length(files):1){
      p = detectedPeaks[[k]]
      #points(p$time, p$mass, pch=1, col=cols[k])
      text(p$time,p$mass, k, cex=.8, col=cols[k])
    }
    points(i,cex=1.3, col=cols, bg=rep('black',length(cols)),pch=21)
    nPlotted=nPlotted+1
	}
  coefs = rbind(coefs, c(i$avgTime,coef(summary(mod))[1:2,1:2],sum((residuals(mod))^2)/length(residuals(mod)),length(residuals(mod))))
  j=j+1
}
colnames(coefs) = c('avgTime', 'avgMass','gr','avgMass.se','gr.se','av.sqrd.gr.residual','# cant')
```

```{r}
par(mfrow=c(2,2), mar=c(3,3,1,1), mgp=c(1.5,.2,0), tck=-.015)
plotCI(coefs[,2], coefs[,3], uiw=coefs[,5], xlim=c(0,cellSizeRange[2]), gap=0, sfrac=0, pch=16,
	xlab='Buoyant mass (pg)', ylab='Mass accumulation rate (pg/hr)')
abline(lm(coefs[,3]~coefs[,2]), col='red')
abline(h=0, col='grey', lty=2)
legend('topright', paste('(+) n=',sum(coefs[,3]>0)))
legend('bottomright', paste('(-) n=', sum(coefs[,3]<0)))

plotCI(coefs[,1], coefs[,3], uiw=coefs[,5], gap=0, sfrac=0,
  xlab='Time (hours)', ylab='Mass accumulation rate (pg/hr)')
abline(h=0, col='grey', lty=2)

plotCI(coefs[,2], coefs[,3]/coefs[,2], uiw=coefs[,5]/coefs[,2], gap=0, sfrac=0,
  xlab='Buoyant mass (pg)', ylab='MAR per mass (/hr)', xlim=c(0,cellSizeRange[2]) )
abline(h=0, col='grey', lty=2)

plotCI(coefs[,1], coefs[,3]/coefs[,2], uiw=coefs[,5]/coefs[,2], gap=0, sfrac=0,
  xlab='Time (hours)', ylab='MAR per mass (/hr)' )
abline(h=0, col='grey', lty=2)
```
```{r}

poscoefs<-subset(coefs,coefs[,3]>0)
negcoefs<-subset(coefs,coefs[,3]<0)
poscoefs<-cbind(poscoefs,poscoefs[,3]-poscoefs[,5])
negcoefs<-cbind(negcoefs,negcoefs[,3]+negcoefs[,5])
Number_within_Zero<-rbind(subset(poscoefs,poscoefs[,8]<0),subset(negcoefs,negcoefs[,8]>0))

Mean_Mass<-mean(coefs[,2])
Mean_MAR<-mean(coefs[,3])
Mean_MAR_Error<-mean(coefs[,5])
Mean_MAR_per_mass<-mean(coefs[,3]/coefs[,2])
Mean_MAR_per_mass_error<-mean(coefs[,5]/coefs[,2])
NumTotalCells<-nrow(coefs)
NumConfidentPosCells<-nrow(subset(poscoefs,poscoefs[,8]>0))
NumConfidentNegCells<-nrow(subset(negcoefs,negcoefs[,8]<0))
Number_within_Error_of_Zero<-nrow(Number_within_Zero)

output<-rbind(Mean_Mass,
                  Mean_MAR,
                  Mean_MAR_Error,
                  Mean_MAR_per_mass,
                  Mean_MAR_per_mass_error,
                  NumTotalCells,
                  NumConfidentPosCells,
                  NumConfidentNegCells,
                  Number_within_Error_of_Zero)

```

```{r}
par(mfrow=c(1,2),mar=c(4,4,3,1))
residcols<-rainbow(length(sensorsToKeep))
residcols<-residcols[trapLengthCutoff:length(sensorsToKeep)]

residlegends<-vector(mode="character",length=length(sensorsToKeep))
for (i in trapLengthCutoff:length(sensorsToKeep)){
  residlegends[i]<-paste(i," Cantilevers matched")
}
residlegends<-residlegends[trapLengthCutoff:length(o)]
residlegends<-residlegends[!is.na(residlegends)]

plot(coefs[,5],coefs[,6],xlab='gr.se', ylab='Mean squared residual',col=residcols[coefs[,7]-trapLengthCutoff+1],pch=16,main='Growth rate errors')
legend("topleft",residlegends,fill =residcols,bty="n",cex=.8)
plot(coefs[,5]/coefs[,2],coefs[,6]/coefs[,2],xlab='Mass Normalized gr.se', ylab='Mass Normalized Mean squared residual',col=residcols[coefs[,7]-trapLengthCutoff+1],pch=16,main='Mass normalized GR. errors')



for (i in 0:(sdtoprune+2)){
mod <- lm(c(0,mean(coefs[,6]/coefs[,2]+i*sd(coefs[,6]/coefs[,2])))~c(mean(coefs[,5]/coefs[,2])+i*sd(coefs[,5]/coefs[,2]),0))
m<-coef(summary(mod))[2,1]
#Y intercept
yintercept <- coef(summary(mod))[1,1]+mean(coefs[,6]/coefs[,2])
  abline(a=yintercept,b=m)
legend(x=0,y=yintercept,legend=paste(i,'SD'),bty="n",xjust=.2)
}

# Bold the line that crosses between the mean for each normalized error parameter
mod <- lm(c(0,mean(coefs[,6]/coefs[,2]))~c(mean(coefs[,5]/coefs[,2]),0))
m<-coef(summary(mod))[2,1]
yintercept <- coef(summary(mod))[1,1]+mean(coefs[,6]/coefs[,2])
  abline(a=yintercept,b=m,col='black',lwd=3)

# Highlight in red the cutoff created by sdtoprune
mod <- lm(c(0,mean(coefs[,6]/coefs[,2]+sdtoprune*sd(coefs[,6]/coefs[,2])))~c(mean(coefs[,5]/coefs[,2])+sdtoprune*sd(coefs[,5]/coefs[,2]),0))
m<-coef(summary(mod))[2,1]
yintercept <- coef(summary(mod))[1,1]+mean(coefs[,6]/coefs[,2])
  abline(a=yintercept,b=m,col='red',lwd=3)

  
keep <- array(dim=c(0,7))
pruned <- array(dim=c(0,7)) 
for (i in 1:nrow(coefs)){
  if ((coefs[i,6]/coefs[i,2]) > (m*coefs[i,5]/coefs[i,2]+yintercept)){
  pruned<-rbind(pruned,coefs[i,])
}  else{
    keep<-rbind(keep,coefs[i,])
  
  }
}


par(mfrow=c(2,2), mar=c(3,3,1,1), mgp=c(1.5,.2,0), tck=-.015)
plotCI(keep[,2], keep[,3], uiw=keep[,5], xlim=c(0,cellSizeRange[2]), gap=0, sfrac=0, pch=16,
	xlab='Buoyant mass (pg)', ylab='Mass accumulation rate (pg/hr)',col='blue')
plotCI(pruned[,2],pruned[,3],uiw=pruned[,5],gap=0, sfrac=0, pch=16,col='red',add=TRUE)
abline(lm(keep[,3]~keep[,2]), col='black')
abline(h=0, col='grey', lty=2)
legend('topright', c(paste('(+) n=',sum(keep[,3]>0)),paste('(+) n=',sum(pruned[,3]>0))),text.col=c('blue','red'))
legend('bottomright', c(paste('(-) n=', sum(keep[,3]<0)),paste('(-) n=',sum(pruned[,3]<0))),text.col=c('blue','red'))

plotCI(keep[,1], keep[,3], uiw=keep[,5], gap=0, sfrac=0,
  xlab='Time (hours)', ylab='Mass accumulation rate (pg/hr)',col='blue')
plotCI(pruned[,1], pruned[,3], uiw=pruned[,5], gap=0, sfrac=0,col='red',add=TRUE)
abline(h=0, col='grey', lty=2)

plotCI(keep[,2], keep[,3]/keep[,2], uiw=keep[,5]/keep[,2], gap=0, sfrac=0,
  xlab='Buoyant mass (pg)', ylab='MAR per mass (/hr)', xlim=c(0,cellSizeRange[2]) ,col='blue')
plotCI(pruned[,2], pruned[,3]/pruned[,2], uiw=pruned[,5]/pruned[,2], gap=0, sfrac=0, col='red',add=TRUE)
abline(h=0, col='grey', lty=2)

plotCI(keep[,1], keep[,3]/keep[,2], uiw=keep[,5]/keep[,2], gap=0, sfrac=0,
  xlab='Time (hours)', ylab='MAR per mass (/hr)' ,col='blue')
plotCI(pruned[,1], pruned[,3]/pruned[,2], uiw=pruned[,5]/pruned[,2], gap=0, sfrac=0,col='red',add=TRUE)
abline(h=0, col='grey', lty=2)
```
```{r}

poscoefs<-subset(keep,keep[,3]>0)
negcoefs<-subset(keep,keep[,3]<0)
poscoefs<-cbind(poscoefs,poscoefs[,3]-poscoefs[,5])
negcoefs<-cbind(negcoefs,negcoefs[,3]+negcoefs[,5])
Number_within_Zero<-rbind(subset(poscoefs,poscoefs[,8]<0),subset(negcoefs,negcoefs[,8]>0))

Mean_Mass<-mean(keep[,2])
Mean_MAR<-mean(keep[,3])
Mean_MAR_Error<-mean(keep[,5])
Mean_MAR_per_mass<-mean(keep[,3]/keep[,2])
Mean_MAR_per_mass_error<-mean(keep[,5]/keep[,2])
NumTotalCells<-nrow(keep)
NumConfidentPosCells<-nrow(subset(poscoefs,poscoefs[,8]>0))
NumConfidentNegCells<-nrow(subset(negcoefs,negcoefs[,8]<0))
Number_within_Error_of_Zero<-nrow(Number_within_Zero)

output<-rbind(sdtoprune,
                  Mean_Mass,
                  Mean_MAR,
                  Mean_MAR_Error,
                  Mean_MAR_per_mass,
                  Mean_MAR_per_mass_error,
                  NumTotalCells,
                  NumConfidentPosCells,
                  NumConfidentNegCells,
                  Number_within_Error_of_Zero)

```


